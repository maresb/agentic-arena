## PLAN — Numbered key decisions with rationale.

1.  **Model Selection: Qwen2.5-VL-72B-Instruct**
    *   **Rationale**: Unanimous consensus across all agents. This model currently offers the best balance of open-weights availability, OCR capability, and dynamic resolution handling.
    *   **Quantization**: **Q4_K_M** (~43GB weights) is the agreed baseline. This allows ~53GB of VRAM headroom on the user's 96GB card, which is critical for handling the large KV cache (~20-26GB) generated by high-resolution visual tokens, as analytically proven by Agent A.

2.  **Preparation Strategy: Window-Aware Cropping with Delta Optimization**
    *   **Step 0 (Verification)**: Run a "sanity check" with a single native 4K screenshot. If the model (via Ollama) downscales it to illegibility (verified by checking if it can read small text), proceed to the main pipeline.
    *   **Step 1 (Delta Check)**: Compute a perceptual hash (pHash) of the current screenshot. If it matches the previous frame (or if the active window hasn't changed), skip processing. This saves massive compute.
    *   **Step 2 (Global Context)**: Resize full screenshot to ~1024px for a quick layout description (JSON).
    *   **Step 3 (Smart Cropping)**:
        *   Use GNOME extension data to crop individual windows at *native resolution*.
        *   **Optimization**: Skip minimized windows. If Z-order is available, skip fully occluded windows. If not, process only the top 3 largest.
        *   **Prompt**: Ask for structured JSON extraction (see Schema below).

3.  **Data Structure & Classification Readiness**
    *   **Schema**:
        ```json
        {
          "timestamp": "ISO8601",
          "delta": "full|partial|none",
          "layout_summary": "string",
          "windows": [
            {
              "title": "VS Code - Project",
              "app": "code",
              "region": "top-left", // Semantic location, not pixel bbox
              "visible_text": ["import os", ...],
              "ui_state": ["sidebar_open", "terminal_visible"],
              "activity_summary": "Editing Python script"
            }
          ]
        }
        ```
    *   **Storage**: Store this JSON + embeddings. Discard raw screenshots.

4.  **Hardware & Implementation Specifics**
    *   **Ollama**: Ensure `num_ctx` is set high (e.g., 32k) to accommodate window crop tokens.
    *   **Platform**: Linux/NixOS. Use `gnome-screenshot` (or D-Bus portal if on Wayland) and `pyvips` for efficient cropping.
    *   **Fallback**: If window geometry is missing, use **Landscape Grid Tiling** (2x2 or 3x2) with 10% overlap, as refined by Agent B.

## CHANGES — Unified diff or precise change descriptions.

No code changes are required. The solution involves a verified architectural plan.

### revised_architecture_final.md

1.  **Input**: `screenshot.png` (3840x2160) + `metadata.json` (GNOME window list).
2.  **Pipeline**:
    *   **Hash Check**: `if pHash(current) == pHash(last): return`
    *   **Global Scan**: `ollama run qwen2.5-vl:72b-q4_k_m "Describe layout"` (resized to 1024px).
    *   **Window Loop**:
        *   `for window in metadata`:
            *   `crop = screenshot.crop(window.rect)`
            *   `ollama run qwen2.5-vl:72b-q4_k_m "Extract text and UI state as JSON" --image crop`
    *   **Synthesize**: Combine into single JSON record.
3.  **Storage**: SQLite with FTS5 enabled for the JSON descriptions.
